import requests  # type: ignore
from bs4 import BeautifulSoup

from data_platform.core.interfaces import BaseExtractor


class BaseHtmlExtractor(BaseExtractor):
    """
    Classe Pai para Scraping HTML.
    J√° traz ferramentas prontas: User-Agent, Soup, Tratamento de Erro.
    """

    def get_soup(self, url: str):
        """M√©todo utilit√°rio que todo scraper filho vai usar."""
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...",
            "Accept-Language": "pt-BR,pt;q=0.9",
        }
        print(f"üåê [Scraper] Acessando: {url}")
        try:
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            return BeautifulSoup(response.text, "html.parser")
        except Exception as e:
            print(f"‚ùå Erro de conex√£o: {e}")
            return None

    # O m√©todo extract() continua abstrato. O filho √â OBRIGADO a implementar.
